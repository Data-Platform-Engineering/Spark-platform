name: Upload to S3

on:
  push:
    branches:
      - "**"
    paths:
      - "spark/*.py"

jobs:
  upload:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo content
        uses: actions/checkout@v4

      - uses: keithweaver/aws-s3-github-action@v1.0.0
        with:
          command: cp
          source: spark/demo.py
          destination: s3://spark-job-source-datasets/folder/demo.py
          aws_access_key_id: ${{ secrets.AWS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws_region: eu-central-1
