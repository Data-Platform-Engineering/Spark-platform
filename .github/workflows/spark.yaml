name: Upload to S3

on:
  push:
    branches:
      - "**"
    paths:
      - "**/*.py"

jobs:
  upload:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@master
      - uses: shallwefootball/s3-upload-action@master
        with:
          aws_key_id: ${{ secrets.AWS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY}}
          aws_bucket: spark-job-data-input
          source_dir: 'spark'
          destination_dir: /spark_input_data/